"""
Strategy para ingesta de PDFs con optimizaciÃ³n de memoria.
Guarda PDF en GridFS ANTES de publicar evento para liberar memoria inmediatamente.
"""
import logging
import asyncio
from typing import Any, Dict, Optional
from fastapi import UploadFile

from app.strategies.ingest_strategy import IngestStrategy
from app.domain.entities import User, Plan
from app.infra.event_bus import get_event_bus
from app.domain.events import PdfIngestStartedEvent
from app.infra.job_repository import JobRepository
from app.infra.pdf_storage import PdfStorage
from app.config import settings
from pymongo import MongoClient

logger = logging.getLogger(__name__)


class PdfIngestStrategy(IngestStrategy):
    """
    Estrategia optimizada para ingesta de PDFs con gestiÃ³n de memoria.
    
    OptimizaciÃ³n de Memoria:
    1. Guarda PDF en GridFS ANTES de publicar evento
    2. Libera pdf_bytes inmediatamente
    3. Evento NO contiene pdf_bytes (solo job_id)
    4. Listener lee de GridFS cuando necesita
    
    Resultado: RAM usage <100MB en lugar de 8GB
    """
    
    def __init__(self):
        self.event_bus = get_event_bus()
        
        # Inicializar dependencias
        client = MongoClient(settings.mongo_uri)
        meta_db = client[settings.mongo_meta_db]
        
        self.job_repo = JobRepository(meta_db)
        self.pdf_storage = PdfStorage(meta_db)
    
    async def validate(self, user: User, plan: Plan, source: UploadFile) -> None:
        """Validar tamaÃ±o del PDF"""
        if hasattr(source, 'size') and source.size:
            size_bytes = source.size
        else:
            content = await source.read()
            size_bytes = len(content)
            await source.seek(0)
        
        size_mb = size_bytes / (1024 * 1024)
        
        if size_mb > plan.pdf_max_size_mb:
            raise ValueError(
                f"PDF too large: {size_mb:.2f}MB exceeds plan limit of {plan.pdf_max_size_mb}MB"
            )
        
        logger.info(f"âœ… PDF validation passed: {size_mb:.2f}MB <= {plan.pdf_max_size_mb}MB")
    
    async def process(
        self,
        user_id: str,
        project_id: str,
        collection: str,
        source: UploadFile,
        document_id: Optional[str] = None,
        metadata: Optional[Dict] = None,
        chunk_size: int = 500,
        plan: Optional[Any] = None,
    ) -> str:
        """
        Iniciar procesamiento con optimizaciÃ³n de memoria.
        
        Returns:
            job_id: ID del trabajo
        """
        job_id = self._generate_job_id()
        doc_id = self._generate_document_id(document_id)
        plan_name = plan.name if plan else "Free"
        
        # 1. Leer PDF (~100ms)
        pdf_bytes = await source.read()
        size_bytes = len(pdf_bytes)
        
        logger.info(f"ðŸ“„ PDF read: job_id={job_id}, size={size_bytes/1024:.2f}KB")
        
        # 2. Crear job (~50ms)
        self.job_repo.create(
            job_id=job_id,
            user_id=user_id,
            project_id=project_id,
            collection_name=collection,
            job_type="pdf_ingest",
            metadata={
                "filename": source.filename,
                "size_bytes": size_bytes,
                "chunk_size": chunk_size,
                "document_id": doc_id,
                "plan_name": plan_name,
                "user_metadata": metadata or {}
            }
        )
        
        # 3. Publicar evento INMEDIATAMENTE (fire-and-forget)
        asyncio.create_task(
            self._process_pdf_background(
                job_id=job_id,
                pdf_bytes=pdf_bytes,
                plan_name=plan_name,
                user_id=user_id,
                project_id=project_id,
                collection=collection,
                size_bytes=size_bytes,
                filename=source.filename
            )
        )
        
        logger.info(f"âœ… PDF ingest queued: job_id={job_id}")
        
        # 4. Retornar job_id INMEDIATAMENTE (<1s)
        return job_id
    
    async def _process_pdf_background(
        self,
        job_id: str,
        pdf_bytes: bytes,
        plan_name: str,
        user_id: str,
        project_id: str,
        collection: str,
        size_bytes: int,
        filename: str
    ):
        """
        Procesar PDF en background:
        1. Guardar en GridFS
        2. Publicar evento PdfSavedToGridFSEvent (event-driven puro)
        3. Liberar memoria
        """
        try:
            # 1. Guardar en GridFS
            logger.info(f"ðŸ’¾ Saving PDF to GridFS (background): job_id={job_id}")
            
            content_hash = await self.pdf_storage.save_or_reuse(
                pdf_bytes=pdf_bytes,
                metadata={"job_id": job_id, "plan_name": plan_name}
            )
            
            logger.info(f"âœ… PDF saved to GridFS: job_id={job_id}, hash={content_hash[:8]}...")
            
            # 2. Publicar evento indicando que PDF estÃ¡ guardado y listo
            from app.domain.events import PdfSavedToGridFSEvent
            
            await self.event_bus.publish(PdfSavedToGridFSEvent(
                user_id=user_id,
                project_id=project_id,
                collection=collection,
                pdf_size_bytes=size_bytes,
                pdf_filename=filename,
                job_id=job_id,
                content_hash=content_hash,
            ))
            
            logger.info(f"ðŸ“¤ PdfSavedToGridFSEvent published: job_id={job_id}")
            
            # 3. Liberar memoria (PDF ya estÃ¡ en GridFS)
            del pdf_bytes
            import gc
            gc.collect()
            logger.info(f"ðŸ—‘ï¸  PDF memory released: job_id={job_id}")
            
        except Exception as e:
            logger.error(f"âŒ Background processing failed: {e}")
            self.job_repo.update_status(job_id, "failed", error=str(e))
